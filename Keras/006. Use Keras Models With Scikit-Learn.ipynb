{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn 라이브러리는 기계 학습을 위한 가장 인기있는 라이브러리 중 하나이다. 여기에서는 scikit-learn 라이브러리를 사용하여 Keras의 딥러닝 모델을 wrapping하는 방법을 이야기하고자 한다.\n",
    "\n",
    "- Scikit-learn 기계 학습 라이브러리와 함께 사용할 Keras 모델을 wrapping하는 방법.\n",
    "- scikit-learn에서 cross validation을 이용하여 Keras 모델을 평가하는 방법.\n",
    "- scikit-learn에서 grid search을 이용하여 Keras 모델의 하이퍼 파라미터를 조정하는 방법."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "\n",
    "Keras는 Python에서 딥러닝 모델을 학습하기 위한 좋은 라이브러리이지만, 말 그대로 딥러닝을 위한 것이지, 전반적인 기계학습을 위한 것은 아니다. 실제로 Keras는 딥러닝 모델을 빠르고 간단하게 정의하고 구축하는 데 필요한 것에만 초점을 두는 미니멀리즘을 추구한다.\n",
    "\n",
    "Python의 scikit-learn 라이브러리는 효율적인 수치 계산을 위해 SciPy 스택을 기반으로 한다. 범용 기계 학습을 위한 많은 기능을 갖춘 라이브러리이며, 딥러닝 모델 개발에 유용한 많은 유틸리티를 제공한다.\n",
    "\n",
    "Keras 라이브러리는 딥러닝 모델을 위한 편리한 래퍼를 제공하며, 여기에서는 Keras에서 분류 신경망 모델을 생성하되, 여기에 KerasClassifier 래퍼를 통해 scikit-learn 라이브러리를 사용하는 예를 살펴볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Stratified Cross Validation으로 모델 평가\n",
    "\n",
    "Keras의 KerasClassifier클래스와 KerasRegressor클래스는 모델 빌드를 위해 호출할 함수이며, 여기에는 build_fn 인수가 있다. 이 인수를 위해 모델을 먼저 정의하고 컴파일 한 후 그 모델을 그대로 반환하는 함수를 만들어야 한다.\n",
    "\n",
    "아래 코드에서는 간단한 다층 신경망을 만드는 함수 create model() 함수를 정의한다.\n",
    "\n",
    "이 함수 이름을 KerasClassifier 클래스의 build_fn 인수에 전달한다. 또한 epochs=150, batch_size=10의 추가 인수를 전달한다. 이들은 자동으로 번들로 묶여서 KerasClassifier 클래스에 의해 내부적으로 호출되는 fit() 함수에 전달된다.\n",
    "\n",
    "아래 코드에서는 scikit-learn 라이브러리의 StratifiedKFold를 사용하여 10-fold stratified cross validation을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696514024761\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    "\n",
    "# 모델을 생성하는 함수. 이 함수 자체가 KerasClassifier의 인수에 대한 입력이 될 것이다.\n",
    "def create_model():\n",
    "    # 모델 정의\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # 모형 적합\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 고정 시드 값으로 초기화\n",
    "seed = 123\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Pima Indians Diabetes 데이터 불러오기\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "\n",
    "# 입력 변수와 출력 변수를 구분하기\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# 모델 정의\n",
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# 10-fold cross validaion을 이용한 모형 평가\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제를 실행하면 10-fold cross validaion을 통해, 총 10개의 모델이 생성되고 각각 평가되며, 최종작으로는 이들을 평균한 정확도가 표시된다.\n",
    "\n",
    "Keras 모델이 랩핑되면 이와 같이 모델을 평가하는 과정이 크게 간소화 될 수 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 모델의 매개변수를 Grid Search를 이용하여 탐색해보기\n",
    "\n",
    "위의 코드는 Keras의 딥러닝 모델을 래핑하고 scikit-learn 라이브러리의 함수에서 사용하는 것이 얼마나 쉬운지를 보여주기 위한 코드였다.\n",
    "\n",
    "이제 한 단계 더 나아가보자. 위 예제로부터 우리는 fit() 함수에 인수를 전달할 수 있다는 것을 이미 알고 있다. KerasClassifier 래퍼를 만들 때 build_fn 인수에 지정하기 위한 함수에도 인수를 사용할 수 있다.\n",
    "\n",
    "또한 다음 코드에서는 grid search를 이용하여 신경망 모델의 여러 구성을 평가하고 최상의 성능을 제공하는 조합을 찾아보고자 한다. create_model() 함수에는 optimizer와 init이라는 인수가 있는데, 둘 다 기본 값이 있어야 한다. 이를 통해 네트워크에 대한 다양한 최적화 알고리즘과 가중치 초기화 체계를 사용했을 때의 효과를 평가할 수 있다.\n",
    "\n",
    "우선 모델을 만든 후에, 검색하고자 하는 매개변수의 값 배열을 정의한다. 구체적으로는 다음과 같습니다.\n",
    "\n",
    "- Optimizer\n",
    "- Initializer\n",
    "- Number of epochs\n",
    "- Batches\n",
    "\n",
    "옵션이 사전에 지정되고, GridSearchCV라는 scikit-learn 클래스에 내장된 함수로 전달된다. 이 클래스는 optimizer, initializer, epoch 및 batch의 조합에 대한 매개 변수(2 × 3 × 3 × 3)의 각 조합에 따른 각 신경망 모델을 평가한다. 그런 다음 각 조합은 기본값으로 3-fold stratified cross validation을 통해 평가가 된다.\n",
    "\n",
    "사실 이러한 과정은 계산에 걸리는 시간 때문에 가볍게 사용하기 위한 방법은 아니다. 합리적인 시간 내에 완료 할 수 있는 더 작은 데이터 subset을 이용하여 작은 실험설계를 하는 것이 유용 할 수 있다. 아래 코드도 CPU만 사용하는 워크스테이션에는 구동이 완료되기까지 대략 5분이 넘는 시간이 걸릴 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.760417 using {'batch_size': 10, 'epochs': 150, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.690104 (0.025976) with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.658854 (0.043537) with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.692708 (0.009207) with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.716146 (0.025780) with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.694010 (0.041626) with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.723958 (0.018688) with: {'batch_size': 5, 'epochs': 50, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.731771 (0.020505) with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.734375 (0.012758) with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.740885 (0.022402) with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.727865 (0.009207) with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.742188 (0.011500) with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.723958 (0.022402) with: {'batch_size': 5, 'epochs': 100, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.700521 (0.030647) with: {'batch_size': 5, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.730469 (0.024910) with: {'batch_size': 5, 'epochs': 150, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.729167 (0.008027) with: {'batch_size': 5, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.740885 (0.025780) with: {'batch_size': 5, 'epochs': 150, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.746094 (0.027805) with: {'batch_size': 5, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.729167 (0.024774) with: {'batch_size': 5, 'epochs': 150, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.670573 (0.004872) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.658854 (0.051855) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.703125 (0.011500) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.701823 (0.015733) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.697917 (0.033502) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.701823 (0.013279) with: {'batch_size': 10, 'epochs': 50, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.634115 (0.067382) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.467448 (0.151098) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.710938 (0.032369) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.730469 (0.019401) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.710938 (0.003189) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.722656 (0.011500) with: {'batch_size': 10, 'epochs': 100, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.697917 (0.014382) with: {'batch_size': 10, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.686198 (0.022402) with: {'batch_size': 10, 'epochs': 150, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.738281 (0.019918) with: {'batch_size': 10, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.729167 (0.025582) with: {'batch_size': 10, 'epochs': 150, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.733073 (0.033197) with: {'batch_size': 10, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.760417 (0.021236) with: {'batch_size': 10, 'epochs': 150, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.554688 (0.152327) with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.665365 (0.038976) with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.687500 (0.012758) with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.690104 (0.004872) with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.682292 (0.009744) with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.700521 (0.021236) with: {'batch_size': 20, 'epochs': 50, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.686198 (0.012075) with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.695313 (0.008438) with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.667969 (0.025516) with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.703125 (0.033754) with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.694010 (0.022628) with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.704427 (0.022402) with: {'batch_size': 20, 'epochs': 100, 'optimizer': 'adam', 'init': 'uniform'}\n",
      "0.682292 (0.024150) with: {'batch_size': 20, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'glorot_uniform'}\n",
      "0.683594 (0.006379) with: {'batch_size': 20, 'epochs': 150, 'optimizer': 'adam', 'init': 'glorot_uniform'}\n",
      "0.694010 (0.030647) with: {'batch_size': 20, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'normal'}\n",
      "0.729167 (0.012890) with: {'batch_size': 20, 'epochs': 150, 'optimizer': 'adam', 'init': 'normal'}\n",
      "0.730469 (0.011500) with: {'batch_size': 20, 'epochs': 150, 'optimizer': 'rmsprop', 'init': 'uniform'}\n",
      "0.723958 (0.021236) with: {'batch_size': 20, 'epochs': 150, 'optimizer': 'adam', 'init': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy\n",
    "\n",
    "# 모델을 생성하는 함수. 이 함수 자체가 KerasClassifier의 인수에 대한 입력이 될 것이다.\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # 모델 정의\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    # 모형 적합\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 고정 시드 값으로 초기화\n",
    "seed = 123\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Pima Indians Diabetes 데이터 불러오기\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "\n",
    "# 입력 변수와 출력 변수를 구분하기\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# 모델 정의\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# epochs, batch size, optimizer의 Grid Search\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "inits = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = [50, 100, 150]\n",
    "batches = [5, 10, 20]\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# 결과 요약\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
